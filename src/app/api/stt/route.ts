import { NextResponse } from 'next/server';
import fs from 'fs';
import path from 'path';
import OpenAI from 'openai';
import ffmpeg from 'fluent-ffmpeg';
import ffmpegPath from 'ffmpeg-static';

// ØªÙ†Ø¸ÛŒÙ… Ù…Ø³ÛŒØ± FFmpeg
if (ffmpegPath) {
  ffmpeg.setFfmpegPath(ffmpegPath);
}

export async function POST(req: Request) {
  try {
    const apiKey = process.env.GROQ_API_KEY;
    
    if (!apiKey) {
        return NextResponse.json({ error: "API Key ÛŒØ§ÙØª Ù†Ø´Ø¯" }, { status: 500 });
    }

    const groq = new OpenAI({
        apiKey: apiKey,
        baseURL: "https://api.groq.com/openai/v1"
    });

    const formData = await req.formData();
    const file = formData.get('audio') as Blob;
    
    if (!file) return NextResponse.json({ error: 'No file' }, { status: 400 });

    const buffer = Buffer.from(await file.arrayBuffer());
    
    // Ø§ØµÙ„Ø§Ø­ Û±: ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ Ø±Ø§ Ø¨Ø¯ÙˆÙ† Ù¾Ø³ÙˆÙ†Ø¯ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ FFmpeg Ø®ÙˆØ¯Ø´ Ù‡Ø¯Ø± ÙØ§ÛŒÙ„ Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†Ø¯
    // Ø§ÛŒÙ† Ú©Ø§Ø± Ù…Ø´Ú©Ù„ ÙØ±Ù…Øª m4a Ø¢ÛŒÙÙˆÙ† Ø±Ø§ Ø­Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    const tempInput = path.join(process.cwd(), `input_${Date.now()}`); 
    const tempOutput = path.join(process.cwd(), `output_${Date.now()}.mp3`);
    
    fs.writeFileSync(tempInput, buffer);

    console.log("ğŸš€ Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ÙØ±Ù…Øª Ù‡ÙˆØ´Ù…Ù†Ø¯...");

    // ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ MP3 Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
    await new Promise((resolve, reject) => {
        ffmpeg(tempInput)
            .toFormat('mp3')
            .on('end', resolve)
            .on('error', (err) => reject(err))
            .save(tempOutput);
    });

    // Ø§ØµÙ„Ø§Ø­ Û²: Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‚Øª Ùˆ Ø§ØµÙ„Ø§Ø­ Ø¬Ù…Ù„Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    const transcription = await groq.audio.transcriptions.create({
      file: fs.createReadStream(tempOutput),
      model: "whisper-large-v3",
      language: "fa", // Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ
      response_format: "json",
      // Ø§ÛŒÙ† Ø®Ø· Ø¬Ø§Ø¯Ùˆ Ù…ÛŒâ€ŒÚ©Ù†Ø¯! Ø¨Ù‡ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø²Ù…ÛŒÙ†Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯:
      prompt: "Ù…ØªÙ† Ú¯ÙØªØ§Ø± Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø³Ù„ÛŒØ³ØŒ Ø¨Ø§ Ø¹Ù„Ø§Ø¦Ù… Ù†Ú¯Ø§Ø±Ø´ÛŒ ØµØ­ÛŒØ­ Ùˆ Ù†ÛŒÙ…â€ŒÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø³Øª ØªØ§ÛŒÙ¾ Ú©Ù†."
    });

    // Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
    try {
        if (fs.existsSync(tempInput)) fs.unlinkSync(tempInput);
        if (fs.existsSync(tempOutput)) fs.unlinkSync(tempOutput);
    } catch (e) { console.error("Cleanup error", e); }

    console.log("âœ… Ù†ØªÛŒØ¬Ù‡:", transcription.text);

    // Ø§ØµÙ„Ø§Ø­ Û³: Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù…Ù†Ø¨Ø¹
    // Ø§Ú¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø§Ø² Ø´ÙˆØ±ØªÚ©Ø§Øª Ø¨ÛŒØ§ÛŒØ¯ Ø§ÛŒÙ† Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø±Ø§ Ù…ÛŒâ€ŒØ¨ÛŒÙ†ÛŒØ¯
    const finalText = transcription.text ? `ğŸ¤– ${transcription.text}` : "";

    return NextResponse.json({ 
        text: finalText,
        mode: "groq-whisper-optimized"
    });

  } catch (error: any) {
    console.error('Groq Error:', error);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}