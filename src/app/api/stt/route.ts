import { NextResponse } from 'next/server';
import fs from 'fs';
import path from 'path';
import OpenAI from 'openai';
import ffmpeg from 'fluent-ffmpeg';
import ffmpegPath from 'ffmpeg-static';

if (ffmpegPath) ffmpeg.setFfmpegPath(ffmpegPath);

export async function POST(req: Request) {
  try {
    const apiKey = process.env.GROQ_API_KEY;
    if (!apiKey) return NextResponse.json({ error: "API Key Not Found" }, { status: 500 });

    const groq = new OpenAI({ apiKey: apiKey, baseURL: "https://api.groq.com/openai/v1" });

    const formData = await req.formData();
    const file = formData.get('audio') as Blob;
    if (!file) return NextResponse.json({ error: 'No file' }, { status: 400 });

    // 1. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„
    const buffer = Buffer.from(await file.arrayBuffer());
    const uniqueId = Date.now();
    const tempInput = path.join(process.cwd(), `input_${uniqueId}`); 
    const tempOutput = path.join(process.cwd(), `output_${uniqueId}.mp3`);
    fs.writeFileSync(tempInput, buffer);

    await new Promise((resolve, reject) => {
        ffmpeg(tempInput).toFormat('mp3').on('end', resolve).on('error', reject).save(tempOutput);
    });

    // 2. ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† (Whisper Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª Ú©Ø§Ù…Ù„)
    console.log("\nğŸ¤ ================= NEW REQUEST =================");
    console.log("ğŸ¤ Step 1: Whisper Analysis (Verbose Mode)...");
    
    const transcription = await groq.audio.transcriptions.create({
      file: fs.createReadStream(tempOutput),
      model: "whisper-large-v3",
      language: "fa",
      response_format: "verbose_json", // Ø¯Ø±ÛŒØ§ÙØª Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ù…Ø±Ù‡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†
    });

    const rawText = transcription.text;
    
    // Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ù…Ø±Ù‡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† logprobs Ø³Ú¯Ù…Ù†Øªâ€ŒÙ‡Ø§)
    // Ù‡Ø±Ú†Ù‡ Ø¨Ù‡ 0 Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ± Ø¨Ø§Ø´Ø¯ (Ù…Ø«Ù„Ø§ -0.1) ÛŒØ¹Ù†ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø¨Ø§Ù„Ø§ØªØ± Ø§Ø³Øª
    let avgLogprob = -1.0; 
    if (transcription.segments && transcription.segments.length > 0) {
        const sum = transcription.segments.reduce((acc: any, seg: any) => acc + seg.avg_logprob, 0);
        avgLogprob = sum / transcription.segments.length;
    }

    console.log(`ğŸ“Š Confidence Score: ${avgLogprob.toFixed(4)}`);
    console.log("ğŸ“ Raw Text:", rawText);
    console.log("----------------------------------------------");

    try {
        if (fs.existsSync(tempInput)) fs.unlinkSync(tempInput);
        if (fs.existsSync(tempOutput)) fs.unlinkSync(tempOutput);
    } catch (e) { /* cleanup */ }

    if (!rawText || rawText.trim().length === 0) return NextResponse.json({ text: "" });

    // 3. Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† Û³ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡
    console.log("âš”ï¸  Step 2: Strategy Battle...");

    // A. Ù…Ø­Ø§ÙØ¸Ù‡â€ŒÚ©Ø§Ø± (ÙÙ‚Ø· Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒâ€ŒÙ‡Ø§ Ùˆ Ø¹Ù„Ø§Ø¦Ù… Ù†Ú¯Ø§Ø±Ø´ÛŒ)
    const promptConservative = `
    You are a strictly conservative Persian Editor.
    Task: Fix ONLY punctuation and English technical terms (to Latin).
    Constraints: DO NOT fix typos like "Ø«ÙˆÙ…". DO NOT change casual style. Output ONLY text.
    `;

    // B. Ù…ØªØ¹Ø§Ø¯Ù„ (Ø§ØµÙ„Ø§Ø­ Ø§Ù…Ù„Ø§ÛŒÛŒ + Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ + Ø­ÙØ¸ Ù„Ø­Ù†)
    const promptBalanced = `
    You are a smart Persian Editor.
    Rules:
    1. Fix spelling errors (e.g. "ØªØ³Øª Ø«ÙˆÙ…" -> "ØªØ³Øª Ø³ÙˆÙ…").
    2. Convert English tech terms to Latin.
    3. KEEP the user's casual tone (e.g. keep "Ù…ÛŒÚ©Ù†Ù‡").
    Output ONLY text.
    `;

    // C. ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¨Ø§ Ù…Ø«Ø§Ù„ (Few-Shot)
    const promptFewShot = `
    You are a Persian Text Corrector. Follow these examples:
    Input: "ØªØ³Øª Ø«ÙˆÙ…." -> Output: "ØªØ³Øª Ø³ÙˆÙ…."
    Input: "Ù†Ú©Ø³ Ø¬ÛŒ Ø§Ø³." -> Output: "Next.js."
    Input: "Ù‚Ø³Øª ÙˆØ§Ù…." -> Output: "Ù‚Ø³Ø· ÙˆØ§Ù…."
    Task: Correct the input based on patterns.
    `;

    // Ø§Ø¬Ø±Ø§ÛŒ Ù…ÙˆØ§Ø²ÛŒ (ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ØªØ³ØªØŒ Ø¯Ø± Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ ÙÙ‚Ø· ÛŒÚ©ÛŒ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
    const [resConservative, resBalanced, resFewShot] = await Promise.all([
        groq.chat.completions.create({ messages: [{ role: "system", content: promptConservative }, { role: "user", content: rawText }], model: "llama-3.3-70b-versatile", temperature: 0 }),
        groq.chat.completions.create({ messages: [{ role: "system", content: promptBalanced }, { role: "user", content: rawText }], model: "llama-3.3-70b-versatile", temperature: 0.1 }),
        groq.chat.completions.create({ messages: [{ role: "system", content: promptFewShot }, { role: "user", content: rawText }], model: "llama-3.3-70b-versatile", temperature: 0.1 })
    ]);

    const textConservative = resConservative.choices[0]?.message?.content?.trim();
    const textBalanced = resBalanced.choices[0]?.message?.content?.trim();
    const textFewShot = resFewShot.choices[0]?.message?.content?.trim();

    // 4. Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ (Conditional Logic)
    let textSmart = "";
    let smartDecision = "";

    if (avgLogprob > -0.25) {
        // Ú©ÛŒÙÛŒØª Ø¹Ø§Ù„ÛŒ -> Ø¯Ø³Øª Ù†Ø²Ù† (ÛŒØ§ ÙÙ‚Ø· Ù…Ø­Ø§ÙØ¸Ù‡â€ŒÚ©Ø§Ø±)
        smartDecision = "ğŸŸ¢ High Confidence (Raw Text / Conservative)";
        textSmart = textConservative || rawText; // ØªØ±Ø¬ÛŒØ­Ø§Ù‹ Ù…Ø­Ø§ÙØ¸Ù‡â€ŒÚ©Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø¹Ù„Ø§Ø¦Ù… Ù†Ú¯Ø§Ø±Ø´ÛŒ
    } else if (avgLogprob > -0.7) {
        // Ú©ÛŒÙÛŒØª Ù…ØªÙˆØ³Ø· -> Ø§ØµÙ„Ø§Ø­ Ù‡ÙˆØ´Ù…Ù†Ø¯
        smartDecision = "ğŸŸ¡ Medium Confidence (Balanced Strategy)";
        textSmart = textBalanced || rawText;
    } else {
        // Ú©ÛŒÙÛŒØª Ù¾Ø§ÛŒÛŒÙ† (Ù†ÙˆÛŒØ²) -> Ù…Ø­Ø§ÙØ¸Ù‡â€ŒÚ©Ø§Ø± Ø¨Ø§Ø´ Ú©Ù‡ ØªÙˆÙ‡Ù… Ù†Ø²Ù†ÛŒ
        smartDecision = "ğŸ”´ Low Confidence (Conservative / Raw)";
        textSmart = rawText; // Ø¯Ø± Ù†ÙˆÛŒØ² Ø´Ø¯ÛŒØ¯ØŒ Ù…ØªÙ† Ø®Ø§Ù… Ø§Ù…Ù†â€ŒØªØ± Ø§Ø³Øª
    }

    // Ú†Ø§Ù¾ Ù†ØªØ§ÛŒØ¬
    console.log("ğŸ›¡ï¸  Strategy A (Conservative):", textConservative);
    console.log("âš–ï¸  Strategy B (Balanced):    ", textBalanced);
    console.log("ğŸ’¡ Strategy C (Few-Shot):    ", textFewShot);
    console.log(`ğŸ§  Strategy D (Smart Logic):  [${smartDecision}] \n   â†³ Result: ${textSmart}`);
    console.log("==============================================\n");

    return NextResponse.json({ 
        text: textSmart, // Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ù†Ø±Ù…â€ŒØ§ÙØ²Ø§Ø±ØŒ Ù†ØªÛŒØ¬Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§Ø³Øª
        mode: "battle-mode-smart" 
    });

  } catch (error: any) {
    console.error('Error:', error);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}