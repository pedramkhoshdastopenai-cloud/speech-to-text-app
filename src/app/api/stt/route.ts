import { NextResponse } from 'next/server';
import fs from 'fs';
import path from 'path';
import OpenAI from 'openai';
import ffmpeg from 'fluent-ffmpeg';
import ffmpegPath from 'ffmpeg-static';

// ØªÙ†Ø¸ÛŒÙ… Ù…Ø³ÛŒØ± FFmpeg
if (ffmpegPath) {
  ffmpeg.setFfmpegPath(ffmpegPath);
}

export async function POST(req: Request) {
  try {
    const apiKey = process.env.GROQ_API_KEY;
    if (!apiKey) return NextResponse.json({ error: "API Key ÛŒØ§ÙØª Ù†Ø´Ø¯" }, { status: 500 });

    const groq = new OpenAI({
        apiKey: apiKey,
        baseURL: "https://api.groq.com/openai/v1"
    });

    const formData = await req.formData();
    const file = formData.get('audio') as Blob;
    if (!file) return NextResponse.json({ error: 'No file' }, { status: 400 });

    // 1. Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„
    const buffer = Buffer.from(await file.arrayBuffer());
    const uniqueId = Date.now();
    const tempInput = path.join(process.cwd(), `input_${uniqueId}`); 
    const tempOutput = path.join(process.cwd(), `output_${uniqueId}.mp3`);
    
    fs.writeFileSync(tempInput, buffer);

    // 2. ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ MP3 Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
    await new Promise((resolve, reject) => {
        ffmpeg(tempInput).toFormat('mp3').on('end', resolve).on('error', reject).save(tempOutput);
    });

    // 3. ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† (Whisper - Step 1)
    console.log("ğŸ¤ Step 1: Transcribing Audio...");
    const transcription = await groq.audio.transcriptions.create({
      file: fs.createReadStream(tempOutput),
      model: "whisper-large-v3",
      language: "fa",
      response_format: "json",
    });

    const rawText = transcription.text;
    console.log("ğŸ“ Raw Text:", rawText);

    // Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
    try {
        if (fs.existsSync(tempInput)) fs.unlinkSync(tempInput);
        if (fs.existsSync(tempOutput)) fs.unlinkSync(tempOutput);
    } catch (e) { console.error("Cleanup error", e); }

    if (!rawText || rawText.trim().length === 0) {
        return NextResponse.json({ text: "" });
    }

    // 4. Ø§ØµÙ„Ø§Ø­ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Few-Shot (Llama 3 - Step 2)
    console.log("ğŸ§  Step 2: Intelligent Correction (Few-Shot Strategy)...");
    
    // ğŸ‘‡ Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ø±Ù†Ø¯Ù‡ (Ù…Ø¯Ù„ A) ğŸ‘‡
    const systemPrompt = `
You are a smart Persian Text Corrector.
INPUT: Raw speech-to-text transcript.
OUTPUT: Corrected text.

Follow these examples exactly to understand the style:

Input: "Ù…Ù† Ø±ÙØªÙ… Ø¨Ø§Ù†Ú© ØªØ§ Ù‚Ø³Øª Ø¨Ø¯Ù…."
Output: "Ù…Ù† Ø±ÙØªÙ… Ø¨Ø§Ù†Ú© ØªØ§ Ù‚Ø³Ø· Ø¨Ø¯Ù…." (Context: Bank implies 'Ghest')

Input: "Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù†Ú©Ø³ Ø¬ÛŒ Ø§Ø³ Ø±Ùˆ Ø±Ø§Ù† Ú©Ù†."
Output: "Ø¨Ø±Ù†Ø§Ù…Ù‡ Next.js Ø±Ùˆ Run Ú©Ù†." (Tech terms to English)

Input: "Ø±ÙˆÛŒ Ø³Ø±ÙˆØ± Ù†ÙˆØ¯ Ø¬ÛŒ Ø§Ø³ ÛŒÙ‡ ÙØ§ÛŒÙ„ Ù†ÙˆØª Ú¯Ø°Ø§Ø´ØªÙ…."
Output: "Ø±ÙˆÛŒ Ø³Ø±ÙˆØ± Node.js ÛŒÙ‡ ÙØ§ÛŒÙ„ Note Ú¯Ø°Ø§Ø´ØªÙ…." (Distinguish Node vs Note)

Input: "Ù‡Ø²ÛŒÙ†Ù‡ Ù…ÛŒØ´Ù‡ ØµØ¯ ØªÙˆÙ…Ù† Ù†Ù‡ Ø¯ÙˆÛŒØ³Øª ØªÙˆÙ…Ù†."
Output: "Ù‡Ø²ÛŒÙ†Ù‡ Ù…ÛŒØ´Ù‡ Ø¯ÙˆÛŒØ³Øª ØªÙˆÙ…Ù†." (Keep final correction)

Input: "ÙØ§ÛŒÙ„ Ø±Ùˆ Ú†ÛŒØ² Ú©Ù† Ø¨ÙØ±Ø³Øª."
Output: "ÙØ§ÛŒÙ„ Ø±Ùˆ Ø¨ÙØ±Ø³Øª." (Remove meaningless filler words)

Input: "Ù‚ÛŒÙ…Øª Ú©Ø§Ù„Ø§ Ø³ÙØ± ØªÙˆÙ…Ù† Ø§Ø³Øª."
Output: "Ù‚ÛŒÙ…Øª Ú©Ø§Ù„Ø§ ØµÙØ± ØªÙˆÙ…Ù† Ø§Ø³Øª."

Task: Correct the user input based on these patterns. Return ONLY the corrected text.
    `;

    const correction = await groq.chat.completions.create({
        messages: [
            { role: "system", content: systemPrompt },
            { role: "user", content: rawText }
        ],
        model: "llama3-70b-8192", 
        temperature: 0.1, // Ø¯Ù…Ø§ÛŒ Ù¾Ø§ÛŒÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø±Ø¹Ø§ÛŒØª Ø¯Ù‚ÛŒÙ‚ Ø§Ù„Ú¯ÙˆÙ‡Ø§
    });

    const finalText = correction.choices[0]?.message?.content?.trim() || rawText;
    console.log("âœ… Final Text:", finalText);

    return NextResponse.json({ 
        text: finalText,
        mode: "groq-hybrid-fewshot" 
    });

  } catch (error: any) {
    console.error('Error:', error);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}